---
title: "Henry Mount Soil Climate Database Tutorial"
author: "D.E. Beaudette and J. Wood"
date: "`r Sys.Date()`"
output:
  html_document:
  mathjax: null
jquery: null
smart: no
keep_md: no
---

```{r setup, echo=FALSE, results='hide', warning=FALSE}
# setup
library(knitr, quietly=TRUE)
opts_chunk$set(message=FALSE, warning=FALSE, background='#F7F7F7', fig.align='center', fig.retina=2, dev='png', tidy=FALSE, verbose=FALSE)
options(width=100, stringsAsFactors=FALSE)
```


# Introduction
This document demonstrates how to use the [soilDB](http://ncss-tech.github.io/AQP/soilDB/soilDB-Intro.html) package to download data from the Henry Mount soil climate database. Soil climate data are routinely collected by SSO staff via buried sensor/data-logger devices ("hobos") and now above ground weather stations. The Henry Mount Soil Climate database was established to assist with the management and analysis of these data.


# Setup R Environment
With a recent version of R (>= 2.15), it is possible to get all of the packages that this tutorial depends on via:
```{r install-deps, eval=FALSE}
# run these commands in the R console
install.packages('RColorBrewer', dep=TRUE)
install.packages('reshape', dep=TRUE)
install.packages('dismo', dep=TRUE)
install.packages('rgdal', dep=TRUE)
install.packages('soilDB', dep=TRUE)
# get latest version from GitHub
install.packages('devtools', dep=TRUE)
devtools::install_github("ncss-tech/soilDB", dependencies=FALSE, upgrade_dependencies=FALSE)
```


# Getting and Viewing Data
Soil climate data can be queried by:
 
 * project (typically a soil survey area, "CA630")
 * NASIS user site ID (e.g. "2006CA7920001")
 * MLRA soil survey office (e.g. "2-SON")

and optionally filtered by:

 * start date ("YYYY-MM-DD")
 * end date ("YYYY-MM-DD")
 * sensor type:
    + "all": all available time series data
    + "soiltemp": soil temperature time series
    + "soilVWC": soil volumetric water content time series
    + "airtemp": air temperature time series
    + "waterlevel": water level time series
 
and aggregated to the following granularity:
 * "hour" (houly data are returned if available)
 * "day" (MAST and mean summer/winter temperatures are automatically computed)
 * "week"
 * "month"
 * "year"


Query daily sensor data associated with the Sequoia / Kings Canyon soil survey.
```{r get-data, fig.width=6, fig.height=7, results='hide'}
library(soilDB)
library(lattice)
library(RColorBrewer)
library(plyr)

# get soil temperature, soil moisture, and air temperature data
x <- fetchHenry(project='CA792')

# check object structure:
str(x, 2)
```

Quick listing of essential site-level data. "Functional years" is the number of years of non-missing data, after grouping data by Julian day. "Complete years" is the number of years that have 365 days of non-missing data. "dslv" is the number of days since the data-logger was last visited.
```{r view-data, fig.width=6, fig.height=7}
# convert into data.frame
d <- as.data.frame(x$sensors)
# keep only information on soil temperature sensors
d <- subset(d, subset=sensor_type == 'soiltemp')
# check top 6 rows and select columns
head(d[, c('user_site_id', 'name', 'sensor_depth', 'MAST', 'Winter', 'Summer', 'STR', 'functional.yrs', 'complete.yrs', 'dslv')])
```


## Plot Data
Note that there are gaps in the data: between site visits and lack of synchronization of site visits with start/end of the year.
```{r plot-time-series, fig.width=10, fig.height=9}
xyplot(sensor_value ~ date_time | name, data=x$soiltemp, main='Daily Soil Temperature (Deg. C)', type=c('l', 'g'), as.table=TRUE, layout=c(2,9), xlab='Date', ylab='Deg C')
xyplot(sensor_value ~ date_time | name, data=x$soilVWC, main='Daily Soil Moisture', type=c('l', 'g'), as.table=TRUE, layout=c(2,6), xlab='Date', ylab='Deg C')
```


Another approach for investigating data gaps, blue: data, grey: no data.
```{r plot-time-series-levelplot, fig.width=9, fig.height=11}
levelplot(factor(!is.na(sensor_value)) ~ doy * factor(year) | name, main='Daily Soil Temperature (Deg. C)',
data=x$soiltemp, layout=c(2,7), col.regions=c('grey', 'RoyalBlue'), cuts=1, 
colorkey=FALSE, as.table=TRUE, scales=list(alternating=3, cex=0.75), 
par.strip.text=list(cex=0.85), strip=strip.custom(bg='yellow'), 
xlab='Julian Day', ylab='Year')

levelplot(factor(!is.na(sensor_value)) ~ doy * factor(year) | name, main='Daily Soil Moisture',
data=x$soilVWC, layout=c(2,4), col.regions=c('grey', 'RoyalBlue'), cuts=1, 
colorkey=FALSE, as.table=TRUE, scales=list(alternating=3, cex=0.75), 
par.strip.text=list(cex=0.85), strip=strip.custom(bg='yellow'), 
xlab='Julian Day', ylab='Year')
```

This style of plotting data can be useful for making comparisons between years. 
```{r plot-time-series-levelplot-2, fig.width=9, fig.height=11.5}
# generate some better colors
cols <- colorRampPalette(rev(brewer.pal(11, 'RdYlBu')), space='Lab', interpolate='spline')

levelplot(sensor_value ~ doy * factor(year) | name, main='Daily Soil Temperature (Deg. C)',
data=x$soiltemp, layout=c(2,7), col.regions=cols,
colorkey=list(space='top'), as.table=TRUE, scales=list(alternating=3, cex=0.75), 
par.strip.text=list(cex=0.85), strip=strip.custom(bg='grey'), 
xlab='Julian Day', ylab='Year')

levelplot(sensor_value ~ doy * factor(year) | name, main='Daily Soil Moisture',
data=x$soilVWC, layout=c(2,4), col.regions=cols,
colorkey=list(space='top'), as.table=TRUE, scales=list(alternating=3, cex=0.75), 
par.strip.text=list(cex=0.85), strip=strip.custom(bg='grey'), 
xlab='Julian Day', ylab='Year')
```


Aggregate over years by sensor / Julian day.
```{r plot-time-series-levelplot-3, fig.width=9, fig.height=6}
# compute MAST by sensor
a <- ddply(x$soiltemp, c('name', 'doy'), .fun=plyr::summarise, soiltemp=mean(sensor_value, na.rm = TRUE))

# re-order sensor names according to MAST
a.mast <- sort(tapply(a$soiltemp, a$name, mean, na.rm=TRUE))
a$name <- factor(a$name, levels=names(a.mast))

levelplot(soiltemp ~ doy * name, main='Daily Soil Temperature (Deg. C)',
data=a, col.regions=cols, xlab='Julian Day', ylab='',
colorkey=list(space='top'), scales=list(alternating=3, cex=0.75, x=list(tick.number=15)))
```



Convert data to percent saturation. (still working on this)
```{r, fig.width=9, fig.height=11.5, eval=FALSE}
fun <- function(i) {
  i$pct.sat <- i$sensor_value / max(i$sensor_value, na.rm = TRUE)
  return(i)
}

# flag days with percent saturation >= 50%
z <- ddply(x$soilVWC, c('sid', 'year'), .fun=fun)
z$pct.sat <- factor(z$pct.sat >= 0.5, levels = c('TRUE', 'FALSE'), labels = c('Moist', 'Dry'))

levelplot(pct.sat ~ doy * factor(year) | name, main='Daily Soil Moisture',
data=z, layout=c(2,4), col.regions=c('grey', 'RoyalBlue'), cuts=1,
colorkey=FALSE, as.table=TRUE, scales=list(alternating=3, cex=0.75), 
par.strip.text=list(cex=0.85), strip=strip.custom(bg='grey'), 
xlab='Julian Day', ylab='Year')
```


# Data Summaries

In the presence of missing data, MAST calculations will be biased towards those data that are not missing. For example, a block of missing data in January will result in an estimated MAST that is too high due to the missing data from the middle of winter. It is possible to estimate (mostly) unbiased MAST values in the presence of some missing data by averaging multiple years of data by Julian day.  This approach will generate reasonable summaries in the presence of missing data, as long as data gaps are "covered" by corresponding data from another year. The longer the period of record and shorter the data gaps, the better.

Soil temperature regime assignment for gelic, cryic, and frigid conditions typically require additional information and are marked with an '*'.

When daily data are queried, unbiased summaries and indices of data "completeness" are calculated.
```{r data-summary, fig.width=6, fig.height=7}
as.data.frame(x$sensors)[which(!is.na(x$sensors$MAST)), c('user_site_id', 'sensor_depth', 'name', 'MAST', 'Winter', 'Summer', 'STR', 'functional.yrs', 'complete.yrs', 'gap.index')]
```


# Water Level Data

Get water level data associated with the "NorthernNY_watertable" project. Water level data are found in `x$waterlevel`.
```{r}
x <- fetchHenry(project='NorthernNY_watertable', gran = 'day', what='waterlevel')
```

Simple time-series style plot, each panel is a water level sensor.
```{r fig.width=10, fig.height=8}
xyplot(sensor_value ~ date_time | name, data=x$waterlevel, type='l', scales=list(alternating=3, cex=0.75), 
par.strip.text=list(cex=0.85), strip=strip.custom(bg='grey'), as.table=TRUE, xlab='', ylab='Water Level (cm)', panel=function(...) {
  panel.grid(-1, -1)
  panel.abline(h=0, col='red', lty=2)
  panel.xyplot(...)
})
```

Apply a threshold and plot TRUE (blue) / FALSE (grey): water level > 25 cm depth.
```{r fig.width=10, fig.height=8}
levelplot(factor(sensor_value > -25) ~ doy * factor(year) | name, main='Daily Water Level > 25 cm Depth',
data=x$waterlevel, col.regions=c('grey', 'RoyalBlue'), cuts=1, 
colorkey=FALSE, as.table=TRUE, scales=list(alternating=3, cex=0.75), 
par.strip.text=list(cex=0.85), strip=strip.custom(bg='yellow'), 
xlab='Julian Day', ylab='Year')
```


Aggregate representation of water level data, by sensor / year: 

  * total records > threshold water level depth
  * fraction of annual records > threshold water level depth
  * maximum consecutive records > threshold water level depth
```{r}
# aggregation of water level data
# i: data.frame, typically subset by ID / year
# level: water table level used for threshold
water.level.threshold <- function(i, level) {
  # apply threshold
  thresh <- i$sensor_value > level
  # compute total records with water level > threshold
  total.records <- length(which(thresh))
  # fraction of records > threshold
  fraction <- total.records / length(na.omit(i$sensor_value))
  
  # get runs of thresholded data
  r <- rle(as.integer(na.omit(thresh)))
  idx <- which(r$values == 1)
  if(length(idx) > 0)
    consecutive.records <- max(r$lengths[idx])
  else
    consecutive.records <- 0
  
  # format and return
  d <- data.frame(total=total.records, fraction=fraction, max.consecutive.records=consecutive.records)
  return(d)
}

# aggregate water level data
wl.agg <- ddply(x$waterlevel, c('name', 'year'), .fun=water.level.threshold, level=-25)

head(wl.agg)
```

Graphical representation of annual water level summaries.
```{r fig.width=8, fig.height=6}
cols <- colorRampPalette(brewer.pal(11, 'RdYlBu'), space='Lab', interpolate='spline', bias=1.75)
levelplot(max.consecutive.records ~ factor(year) * factor(name), data=wl.agg, col.regions = cols, main='Maximum Consecutive Days\n> 25cm Water Level Depth', xlab='', ylab='')

levelplot(fraction ~ factor(year) * factor(name), data=wl.agg, col.regions = cols, main='Fraction of Days / Year\n> 25cm Water Level Depth', xlab='', ylab='')
```


## Water Level and Precipitation
Combine water level data from Henry DB and daily precipitation data from nearby SCAN station (suggested by Ben Marshall).

This example requires the `latticeExtra` package and a couple of small adjustments to make the Henry and SCAN data compatible.
```{r}
library(soilDB)
library(latticeExtra)

# get specific data from Henry:
# water level data only
# as daily means
# do not fill missing days with NA (adjust as needed)
x <- fetchHenry(project='MD021', what='waterlevel', gran = 'day', pad.missing.days = FALSE)
x <- subset(x$waterlevel, name == "Hatboro-155")

# convert Henry date/time into `Date` class: compatibility with SCAN data
x$date_time <- as.Date(x$date_time)

# get data from nearby SCAN station for 2015--2017
x.scan <- fetchSCAN(site.code=2049, year=c(2015,2016,2017))
```

When working with `Date` class values on the x-axis, it is often more convenient to derive the tick locations by hand. Here we generate the `start.date` and `stop.date` tick location using the oldest and latest water level records, then pad with 14 days. `seq.Date()` is helpful for generating a regular sequence of dates that span the calcuated "start" and "stop" dates.
```{r}
# create a new date axis
# using the limits of the water level data and pad days
start.date <- min(x$date_time) - 14
stop.date <- max(x$date_time) + 14
date.axis <- seq.Date(start.date, stop.date, by='2 months')
```


Lattice plots can be saved to regular R objects for further manipulation.
```{r}
# plot water level data, save to object
p.1 <- xyplot(sensor_value ~ date_time, data=x, type=c('l', 'g'), cex=0.75, ylab='Water Level (cm)', xlab='', scales=list(x=list(at=date.axis, format="%b\n%Y"), y=list(tick.number=10)))

# plot precip data, save to object
p.2 <- xyplot(value ~ Date, data=x.scan$PRCP, as.table=TRUE, type=c('h'), strip=strip.custom(bg=grey(0.80)), scales=list(x=list(at=date.axis, format="%b\n%Y")), ylab='Precipitation (in)')

# combine plots into panels (latticeExtra feature)
p.3 <- c(p.1, p.2, layout=c(1,2), x.same=TRUE)
```


Make final adjustments and plot:

  * fix scale labels
  * add a y-axis label for each panel
  * add a title
  * truncate x-axis to the interval `start.date`--`stop.date`, define by the water level data
  * add a custom set of grid lines to each panel
  
```{r fig.width=10, fig.height=7}
update(p.3, scales=list(alternating=3, y=list(rot=0)), ylab=c('Water Level (cm)', 'Precipitation (in)'), main='Daily Values', xlim=c(start.date, stop.date), panel=function(...) {
  panel.xyplot(...)
  panel.abline(v=date.axis, col='grey', lty=3)
  panel.grid(h = -1, v=0, col='grey', lty=3)
})
```




# Additional Ideas

1. Save sites as shape file
```{r save-as-shp, eval=FALSE}
library(rgdal)
writeOGR(x$sensors, dsn='foldername', layer='filename', driver='ESRI Shapefile')
```

2. Overlay site locations on a Google map
```{r map-data, eval=FALSE}
library(dismo)
g <- gmap(x$sensors)
plot(g, interpolate=TRUE)
points(Mercator(x$sensors), col='red')
```

3. Fit a simple model relating MAST to MAAT (PRISM) using soil temperature data from the several MLRA SSO.
```{r, results='hide', eval=FALSE}
library(raster)
library(rms)

# load PRISM mean annual air temp raster
r <- raster('E:/gis_data/prism/final_MAAT_800m.tif')

# function for getting / processing data by MLRA SSO
getData <- function(sso) {
  x <- fetchHenry(sso = sso, what = 'soiltemp')
  x$sensors$maat <- extract(r, x$sensors)
  return(x$sensors@data)
}

# get / process data for select MLRA SSO
# note: takes a couple minutes
res <- ldply(c('2-SON', '2-TEM', '4-DIL'), getData)
```

```{r, fig.width=6, fig.height=6, eval=FALSE}
m <- subset(res, subset=sensor_depth == 50)

plot(MAST ~ maat, data=m)

dd <- datadist(m)
options(datadist="dd")

(m.ols <- ols(MAST ~ rcs(maat), data=m))
plot(Predict(m.ols, conf.type = 'simultaneous'), ylab='MAST', xlab='MAAT (PRISM)')
```


----------------------------
This document is based on `aqp` version `r utils::packageDescription("aqp", field="Version")` and `soilDB` version `r utils::packageDescription("soilDB", field="Version")`.

